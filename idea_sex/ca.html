<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
</head>
<body>
<p>[]( - reversible cellular automata - http://inbound.org/discussion/view/i-am-randy-olson-ai-researcher-and-data-visualization-aficionado-here-to-answer-all-of-your-questions-about-data-visualization</p>
<p>Idea Sex Topic ideas: - uses of cellular automata - role of climate change in current culture - applications of crypto protocols outside of crypto - application of graph theory / math / game theory / modeling to chemistry and related - What is the cloud? -- role of cloud in culture, role of cloud in future, )</p>
<h1 id="cellular-automata">Cellular Automata</h1>
<h2 id="the-idea-of-idea-sex">The idea of idea sex</h2>
<p>Well, it's summer, and with that brings time and impetus for different activities. I have wanted to try a new thing where I just think of ideas: I just write down as many ideas about a certain theme as I can. A week or so ago I found the idea formalized in an answer (TODO ADD LINK). The author of the answer calls the activity &quot;idea sex&quot;, and it's simple: on a daily basis come up with a theme and then try to come up with 10 ideas relating to the theme. The author says that what generally happens is that the first 2-5 ideas are easy, they flow right out of the mind, but after that they become harder. So this summer I intend to give idea sex a try. At some point I may make the theme of idea sex &quot;alternative names for this activity&quot;.</p>
<h1 id="idea-sex-with-cellular-automata-ca">Idea Sex with Cellular Automata (CA)</h1>
<p>Today the topic is <a href="https://en.wikipedia.org/wiki/Cellular_automaton">Cellular Automata</a>.</p>
<ol style="list-style-type: decimal">
<li><p>Reversing Schelling's model. We think of the micro behavior this way: an agent is happy/unhappy based on their neighborhood. Instead of an agent purely reacting to their neighborhood, what happens when a neighbor constructs their neighborhood? In the original model, the extent to which an agent (call it the central agent) has an effect on their environment is to affect the happiness of those around them, which if we only consider a single time step, turns out to have no effect on the happiness of the central agent. Consider a different model where the traits or perhaps race of the neighbors is a construction of the central agent. I think the model would have to adopt traits, and manifest the traits based on the environment. Then to what extent are we modeling genotype phenotype? Has this been done?</p></li>
<li><p>Modeling hydrogen bonding using cellular automata. Is there a way to capture 1/r^2 with a good heuristic in 2-d space? Expand to 3-d space?</p></li>
<li><p>Perhaps more generally that point 2, does there exist a general framework for modeling a system that is modeled via differential equations using cellular automata? To what extent is cellular automata limited by having agents only use local information?</p></li>
<li><p><a href="https://en.wikipedia.org/wiki/Cellular_automaton">Just found an article where you that models employee relations using CA.</a></p></li>
<li><p>Is there a good way to integrate communication complexity into cellular automata? Communication complexity is the idea that it costs time for agents to communicate. Suppose there are <span class="math"><em>n</em></span> agents in the system, then in the course of the system operations there are <span class="math"><em>f</em>(<em>n</em>)</span> communications between agents, where <span class="math"><em>f</em>(<em>n</em>)</span> is some function. For example, if <span class="math"><em>f</em>(<em>n</em>) = <em>n</em><sup>2</sup></span> then there are <span class="math"><em>n</em><sup>2</sup></span> interactions in the system, this probably means that every agent talks to every other agent exactly once. Alternatively, it could be the case that <span class="math"><em>f</em>(<em>n</em>) = 10</span>, which would indicate that no matter how many agents are in the system, there are <span class="math">10</span> instances of agents interacting. Let us quickly compute the communication complexity of Schelling's model. Let's outline the algorithm and compute it step by step. Inputs: <span class="math"><em>n</em></span> agents, <span class="math"><em>m</em> × <em>m</em></span> board, and the model takes <span class="math"><em>l</em></span> steps before it terminates.</p>
<ol style="list-style-type: decimal">
<li>For each agent, compute whether that agent is happy.</li>
<li>Pick an unhappy agent at random. Call this agent the central agent.</li>
<li>Find the nearest empty cell such that the central agent would be happy at that cell. Move the central agent to that cell.</li>
<li>Repeat steps 1-3 until termination condition.</li>
</ol>
<p>And the complexity:</p>
<ol style="list-style-type: decimal">
<li>Since for each agent, we have to compute the happiness, we have to count up the neighbors of each agent. That means this takes <span class="math">8 × #</span> agents. Note that this is an upper bound. In most cases, agents will not have <span class="math">8</span> neighbors.</li>
<li>This takes no communications.</li>
<li>This steps takes a variable number of communications.</li>
</ol>
<p>It depends on how many cells we have to check before we find a cell where the central agent would be happy. For simplicity, suppose we check <span class="math"><em>c</em></span> cells on average. Then the communication complexity would be <span class="math">8<em>c</em></span>. This is another upper bound, as most places don't have <span class="math">8</span> agents surrounding them.</p>
<p>A few clarifications before I wrap up:</p>
<ol style="list-style-type: decimal">
<li>I suppose I should clarify, when I say communication here, I really mean interaction.</li>
<li>We could think of it as an agent wants to know how happy its neighbors are so it walks to each of its neighbors' houses, knocks on the door, and asks them if their race (if the agent can't tell from the color of their skin, but race is a social construct so the color of the skin doesn't matter, but here we are talking about perception of race, ... I digress).</li>
<li>There are faster algorithms where we don't recompute happiness in step 1 every time (we can just computer around where the central agent used to live and moved to), so this is just an upper bound.</li>
</ol>
<p>Besides those caveats, an upper bound for our communication complexity is <span class="math"><em>f</em>(<em>n</em>) = <em>l</em>(8<em>n</em> + 8<em>c</em>)</span> where <span class="math"><em>l</em></span> = number of steps before termination, <span class="math"><em>n</em></span> = number of agents, <span class="math"><em>c</em></span> = number of cells checked before a central agent finds a satisfactory cell.</p>
<p>What is important when analyzing the communication complexity is the relationship between the variables. What I mean is this: <span class="math"><em>l</em></span> has a bigger impact on the value of <span class="math"><em>f</em>(<em>n</em>)</span> than <span class="math"><em>n</em></span> or <span class="math"><em>c</em></span>, so the longer we run our simulation, the more complexity we will have. Another important observation is that there are no proper &quot;squares&quot; in the formula, i.e. there is no <span class="math"><em>n</em><sup>2</sup>, <em>l</em><sup>2</sup>, <em>c</em><sup>2</sup></span> term, but we do have <span class="math"><em>n</em><em>l</em></span> and <span class="math"><em>c</em><em>l</em></span>.</p>
<p>It would be interesting to do a more in depth study of communication complexity as it relates to cellular automata.</p></li>
<li><p>I wonder to what extent the interactions in our world (social relations) are governed by local information? If we say that our information is pretty local, for example the events in Nepal and Africa and India have little impact on my decision on what coffee shop I go to, then what does that say about the idea that we have global responsibility. In Schelling's model, how can an agent on the lower hand side of the board be responsible for segregation on the top right part of the board? They are responsibility due to the fact that they are part of the system, but what does that really mean? This is an idea that I really don't understand yet.</p>
<p>Global responsibility (and its dual, local action) are ideas that I will probably blog about later; it's not worth getting into now.</p></li>
<li><p>Given that last point and others work that I've read, it's becoming increasingly clear that CA have a lot to offer when it comes to understanding the role of humans in a complex society. We can really see how much power agents have, how much they know, what influences them, what doesn't, their effects, and so forth in this limited setting. The problem with using CA is this: when we try to model social relations, we are trying to model emergent behavior, but is very difficult to construct a system with desirable emergent, global behavior (particularly when you only have power over local rules, i.e. how agents interact on a micro scale). I think this idea should instruct us on how we should think about sexism and racism. It's hard to understand the gut of the issue by observing the macro effects. For example, if we think about the bad effects of racism, our minds typically move towards housing segregation, unfair workplaces, unfair wages, unfair incarceration and sentences, etc.. But for some reason those are things it is difficult for us as individual agents to have an effect on. We can, and do, organize together in order to affect the issue, but if we think about that in terms of CA, that's hard to do, and in reality it seems pretty hard to do, seeing as to how rare how it happens and largely ineffective it is (with the huge exception of SOPA). Even Ferguson isn't having a huge impact on the macro behavior. I don't quite know what the take-away is but it has something to do with not simply viewing social issues as things we think about as large phenomena, nor should we merely consider them as local events which we can only have a small affect on, but rather we need to think of the interplay between the micro and macro and the agency that we have in both the micro and macro worlds.</p></li>
<li><p>I wonder if we had a less globalized, less connected, less large society if the analysis in point 6 and 7 would be different. I think the question is really this: is the complexity of society dependent on its breadth and connectedness? My first response is that it reminds me of Melanie Mitchell's assessment of what it means to be complex in her book Complexity. Melanie suggests that what makes a system complex is the amount of interconnections and interdependence in its components. She uses the example of humans. Humans are complex because our genes are highly interconnected, whereas the genes of other organisms are less interconnected, hence they exhibit less complex behavior. Likewise, our society is highly interconnected. You take out any person, any company (with the exception of the &quot;too big to fail&quot;) and our society continues to survive, in many cases our society doesn't so much as blink as eye. There are other people, other companies, other components that can combine to take the place of the missing piece.</p>
<p>I guess my proposition is that yes, the interconnectedness of society is a huge contributor to the complexity of society. In past worlds, or some alternative world, where there is less interconnection between the components of society, society is less robust and less complex, and I believe that this exact behavior is what has been modeled and exhibited by Cellular Automata.</p></li>
<li><p>Could we model an organism - not interactions between organisms - but the organism itself using cellular automata? Seems like another annoying model where we aim for particular emergent properties, a difficult task.</p></li>
<li><p>What about changing the space on which the CA operates. This could mean many things. I could mean thinking of the space as continuous, which SmoothLife does with game of life. Alternatively, what about trying out Schelling model's on a board with hexagonal cells, or triangular cells. I hypothesize that the emergent behavior would not change based on my project of adding random walks to Schelling's model (see link on my website). Perhaps idea 9, where I propose modeling an organism, would be a good instance to employ changing the space of the CA. If you were to model DNA with CA, then I have no idea what the correct space would like look like because you want to capture the facts that sequences of genes as being important, and that genes are interdependent (the functionality of a sequence of genes can be replaced by the combination of various other sequences of genes. LIke what I was talking about earlier with human complexity).</p></li>
</ol>
<p>Phew. That was hard, but worth it. Like a workout.</p>
</body>
</html>
